{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "#### EE-556 Mathematics of Data - Fall 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we consider a binary classification task that we will model using logistic regression. Your goal will be to find a classifier using first-order methods and accelerated gradient descent methods. The first part will consist of more theoretical questions, and the second one will ask you to implement these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  ℹ️ <strong>Information on group based work:</strong>\n",
    "</div>\n",
    "\n",
    "- You are to deliver only 1 notebook per group.\n",
    "- Asking assistance beyond your group is ok, but answers should be individual to the group.\n",
    "- In the event that there was <span style=\"color: red;\">disproportional work done</span> by different group members, let the TAs know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #f00; background-color: #fdd; padding: 10px; border-radius: 5px;\">\n",
    "  ⚠️ Do not forget: Write who are the people in your group as well as their respective SCIPER numbers\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Person 1 **Name**: || Person 1 **SCIPER**:\n",
    "\n",
    "\n",
    "Person 2 **Name**: || Person 2 **SCIPER**:\n",
    "\n",
    "\n",
    "Person 3 **Name**: || Person 3 **SCIPER**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression - 15 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a classic approach to _binary classification_. Before we dive in, let us first define the standard logistic function $\\sigma$ on which most of what follows is built:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\sigma : x \\mapsto \\frac{1}{1 + \\exp{(-x)}}.\n",
    "\\end{equation*}\n",
    "\n",
    "In logistic regression, we model the _conditional probability_ of observing a class label $b$ given a set of features $\\mathbf{a}$. More formally, if we observe $n$ independent samples\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\{(\\mathbf{a}_i,b_i)\\}_{i=1}^n,\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\mathbf{a}_i\\in\\mathbb{R}^p$ and $b_i\\in\\{-1, +1\\}$ is the class label, we _assume_ that $b_i$ given $\\mathbf{a}_i$ is a symmetric Bernouilli random variable with parameter $\\sigma(\\mathbf{a}_i^T\\mathbf{x}^\\natural)$, for some unknown $\\mathbf{x}^\\natural \\in \\mathbb{R}^p$. In other words, we assume that there exists an $\\mathbf{x}^\\natural \\in \\mathbb{R}^p$ such that\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbb{P}(b_i = 1 \\mid \\mathbf{a}_i) = \\sigma(\\mathbf{a}_i^T\\mathbf{x}^\\natural) \\quad \\text{ and } \\quad \\mathbb{P}(b_i = -1 \\mid \\mathbf{a}_i) = 1 - \\sigma(\\mathbf{a}_i^T\\mathbf{x}^\\natural)=  \\sigma( - \\mathbf{a}_i^T\\mathbf{x}^\\natural).\n",
    "\\end{equation*}\n",
    "\n",
    "This is our statistical model. It can be written in a more compact form as follows,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbb{P}(b_i = j \\mid \\mathbf{a}_i) = \\sigma(j \\cdot \\mathbf{a}_i^T\\mathbf{x}^\\natural), \\quad j \\in \\{+1, -1\\}.\n",
    "\\end{equation*}\n",
    "\n",
    "Our goal now is to determine the unknown $\\mathbf{x}^\\natural$ by constructing an estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__ (1 point) We are provided with a set of $n$ independent observations. Show that the negative log-likelihood $f$ can be written as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\t\\begin{aligned}\n",
    "\t\tf(\\mathbf{x}) = -\\log(\\mathbb{P}(b_1, \\dots, b_n | a_1, \\dots, a_n)) & = \\sum_{i=1}^n  \\log(1 + \\exp(- b_i \\mathbf{a}_i^T\\mathbf{x})).\n",
    "\t\\end{aligned}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indpendance enables us to write:\n",
    "\n",
    "$p_\\textbf{x}(\\textbf{b})= \\prod_{i=1}^{n}\\mathbb{P(b_i| a_i)}$\n",
    "\n",
    "It follows, with the help of the log properties and that $\\mathbb{P}(b_i=j \\mid \\mathbf{a}_i) =\\sigma(j\\mathbf{a}_i^T\\mathbf{x})$  that the negative log-likelihood is given by:\n",
    "\n",
    "$f(\\mathbf{x})=-\\log(p_\\textbf{x}(\\textbf{b}))= -\\log(\\prod_{i=1}^{n}\\mathbb{P(b_i| a_i)})= -\\sum_{i=1}^{n}\\log(\\mathbb{P(b_i| a_i)})=-\\sum_{i=1}^{n}\\log(\\sigma(b_i\\mathbf{a}_i^T\\mathbf{x}))=\\sum_{i=1}^{n}\\log(1 + \\exp(- b_i \\mathbf{a}_i^T\\mathbf{x}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b)__ (2 point) Show that the function $u \\mapsto \\log(1 + \\exp(-u))$ is convex. Deduce that $f$ is convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second derivative of $\\log(1 + \\exp(-u))$ gives $\\frac{\\exp(-u)}{(1 + \\exp(-u))^2}$ and the second derivative is positive so, by the definition given by the course (lecture 3, page 28), the function $\\log(1 + \\exp(-u))$ is convex. It follows that $\\log(1 + \\exp(- b_i \\mathbf{a}_i^T\\mathbf{x}))$ is convex and knowing that the sum of convex functions gives a convex functions, we proved that $f$ is convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have just established that the negative log-likelihood is a convex function. So in principle, any local minimum of the maximum likelihood estimator, which is defined as\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbf{x}^\\star_{ML} = \\arg\\min_{\\mathbf{x} \\in \\mathbb{R}^p} f(\\mathbf{x}),\n",
    "\\end{equation*}\n",
    "\n",
    "is a global minimum so it can serve as an estimator of $\\mathbf{x}^\\natural$. But, does the minimum always exist? We will ponder this question in the following three points.\n",
    "\n",
    "__(c)__ (1 point) Explain the difference between infima and minima.  Give an example of a convex function, defined over $\\mathbb{R}$, that does not attain its infimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A minimum of a set is the lowest element contained in this set. An infimum of a set is defined as the highest lower bound of the set, not necessarly contained in the set. For exemple, we can take the convex function $f(x)=\\exp(x)$ over $\\mathbb{R}$, and find that the infimum is 0, but this value is never reached because $\\exp(x)>0$. So the minimum of this function doesn't exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(d)__ (1 point) Let us assume that there exists $\\mathbf{x}_0 \\in \\mathbb{R}^p$ such that \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\forall i\\in\\{1, \\dots, n\\}, \\quad \\quad b_i \\mathbf{a}_i^T\\mathbf{x}_0 > 0.\n",
    "\\end{equation*}\n",
    "\n",
    "This is called _complete separation_ in the literature. Can you think of a geometric reason why this name is appropriate? Think of a 2D example where this can happen (i.e $p=2$) and describe why _complete separation_ is an appropriate name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If such a $\\mathbf{x}_0$ exists, we can perfectly separate the points $\\mathbf{a}_i$ of label $b_i=1$ from the points $\\mathbf{a}_i$ of label $b_i=-1$. On a 2D geometrical perspective, we can see $\\mathbf{x}_0$ as the normal of the line that separates the points of label 1 from the ones of label -1, and thus complete separation is an appropriate name in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, you should see that it is likely that our data satisfies the complete separation assumption. Unfortunately, as you will show in the following question, this can become an obstacle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(e)__ (1 point) In a _complete separation_ setting, i.e, there exists $\\mathbf{x}_0$ such that \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\forall i\\in\\{1, \\dots, n\\}, \\quad \\quad b_i \\mathbf{a}_i^T\\mathbf{x}_0 > 0,\n",
    "\\end{equation*}\n",
    "\n",
    "prove that the function $f$ does not attain its minimum. \n",
    "\n",
    "__Hint__: If the function did have a minimum, would it be above, below or equal to zero? Then think of how $f(2 \\mathbf{x}_0)$ compares with $f(\\mathbf{x}_0)$, how about $f(\\alpha \\mathbf{x}_0)$ for $\\alpha \\rightarrow + \\infty$ ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(\\mathbf{x}_0)= \\sum_{i=1}^n  \\log(1 + \\exp(- b_i \\mathbf{a}_i^T\\mathbf{x}_0))$ and $-b_i \\mathbf{a}_i^T\\mathbf{x}_0 < 0$. \n",
    "\n",
    "Given that the exponential is strictly higher than 0, we can lower bound $\\exp(- b_i \\mathbf{a}_i^T\\mathbf{x}_0)>0$. This implies that:\n",
    "$f(\\mathbf{x}_0)= \\sum_{i=1}^n  \\log(1 + \\exp(- b_i \\mathbf{a}_i^T\\mathbf{x}_0))> \\sum_{i=1}^n  \\log(1)= 0$, because the logarithm is a growing function. So if the function had a minimum it would be zero.\n",
    "We can confirm that by taking $f(\\alpha \\mathbf{x}_0)$ for $\\alpha \\rightarrow + \\infty$ which gives the lower bound of $f$, and not the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have just shown convex functions do not always attain their infimum. So it is possible for the maximum-likelihood estimator $\\mathbf{x}^\\star_{ML}$ to not exist. We will resolve this issue by adding a regularizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we consider the function\n",
    "\n",
    "\\begin{equation*}\n",
    "\tf_\\mu(\\mathbf{x}) = f(\\mathbf{x}) + \\frac{\\mu}{2}\\|\\mathbf{x}\\|_2^2\n",
    "\\end{equation*}\n",
    "with $\\mu> 0$.\n",
    "\n",
    "__(f)__ (1 point) Show that the gradient of $f_\\mu$ can be expressed as \n",
    "\\begin{equation}\n",
    "\t\\nabla f_\\mu(\\mathbf{x}) = \\sum_{i=1}^n -b_i \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})\\mathbf{a}_i + \\mu \\mathbf{x}.\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "__Hint__: Lecture 3 shows you how to proceed with this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can divide $f_\\mu$ in two parts, $f(\\mathbf{x})$ and $\\frac{\\mu}{2}\\|\\mathbf{x}\\|_2^2$.\n",
    "\n",
    "The gradient of $\\frac{\\mu}{2}\\|\\mathbf{x}\\|_2^2$ is obviously $\\mu\\mathbf{x}$\n",
    "\n",
    "For $f(\\mathbf{x})$, we begin by computing the Jacobian of $\\mathbf{h}_i(\\mathbf{x})=\\mathbf{a}_i^T\\mathbf{x}$, which gives $\\mathbf{J}_{h_i}= \\mathbf{a}_i^T$\n",
    "\n",
    "We continue with the Jacobian of $\\log(1 + \\exp(- b_i u))$ which gives, $\\mathbf{J}_{g_i}(u) = -b_i\\frac{\\exp(- b_i u)}{1+\\exp(- b_i u)}$\n",
    "By the chain rule and that the gradient of a sum is the sum of gradient we obtain:\n",
    "\n",
    "$\\mathbf{J}_{f_i}(\\mathbf{x}) = \\mathbf{J}_{g_i}(\\mathbf{h}_i(\\mathbf{x}))\\cdot\\mathbf{J}_{h_i}(\\mathbf{x}) = -b_i\\frac{\\exp(- b_i \\mathbf{a}_i^T\\mathbf{x})}{1+\\exp(- b_i \\mathbf{a}_i^T\\mathbf{x})}\\mathbf{a}_i^T$\n",
    "\n",
    "Using the fact that the gradient of a sum of function is the sum of the individual gradient. We can obtain the individual gradient by taking the transpose of the Jacobian and so we obtain:\n",
    "\n",
    "$\\nabla f_\\mu(\\mathbf{x}) = \\sum_{i=1}^n -b_i\\frac{\\exp(- b_i \\mathbf{a}_i^T\\mathbf{x})}{1+\\exp(- b_i \\mathbf{a}_i^T\\mathbf{x})}\\mathbf{a}_i + \\mu \\mathbf{x}= \\sum_{i=1}^n -b_i \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})\\mathbf{a}_i + \\mu \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(g)__ (1 point) Show that the Hessian of $f_\\mu$ can be expressed as \n",
    "\\begin{equation}\n",
    "\t\\nabla^2 f_\\mu(\\mathbf{x}) = \\sum_{i=1}^{n} \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1 - \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x}))\\mathbf{a}_i\\mathbf{a}_i^T + \\mu \\mathbf{I}.\n",
    "\\tag{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the term $\\frac{\\mu}{2}\\|\\mathbf{x}\\|_2^2$, it is a sum of squares of $x_i$, so it gives just $\\mu \\mathbf{I}$\n",
    "\n",
    "For the second term, it is a bit more complicated. We have to look at the gradient and differentiate term by term. We will take take for $i$ and like before, we will just sum for the $n$ terms\n",
    "\n",
    "We notice that the derivative of $\\sigma(x)$ is $\\sigma(x)(1-\\sigma(x))$. \n",
    "\n",
    "Given that we can compute the Hessian by differentiating each element of the gradient with respect to $\\partial x_m$. We obtain $ a_{i,m} \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1-\\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x}))a_{i,n}$ , with a_{i,n} the n-th value of the i-th variable. This is the partial derivative of the m-th element of gradient with respect to the n-th element of $\\mathbf{x}$.\n",
    "\n",
    "We can then use this formula and add the summation to write the desired expression: \n",
    "\n",
    "$\\nabla^2 f_\\mu(\\mathbf{x}) = \\sum_{i=1}^{n} \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1 - \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x}))\\mathbf{a}_i\\mathbf{a}_i^T + \\mu \\mathbf{I}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is convenient to observe that we can write the Hessian in a more compact form by defining the matrix\n",
    "\\begin{equation}\n",
    "\t\\mathbf{A} = \\begin{bmatrix}\n",
    "        \\leftarrow &  \\mathbf{a}_1^T & \\rightarrow \\\\\n",
    "        \\leftarrow &  \\mathbf{a}_2^T & \\rightarrow \\\\\n",
    "         &  \\ldots &  \\\\\n",
    "        \\leftarrow &  \\mathbf{a}_n^T & \\rightarrow \\\\\n",
    "  \\end{bmatrix}.\n",
    "\\end{equation}\n",
    "It is easy to see that we have\n",
    "\\begin{equation}\n",
    "\t\\nabla^2 f_\\mu(\\mathbf{x}) =  \\mathbf{A}^T \\text{Diag}\\left(\\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1 - \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})) \\right)\\mathbf{A}+ \\mu \\mathbf{I}.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(h)__ (1 point) Show that $f_\\mu$ is $\\mu$-strongly convex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f_\\mu$ is $\\mu$-strongly convex if and only if $\\nabla^2 f_\\mu(\\mathbf{x})\\succeq \\mu \\mathbf{I}$ (from Lemma at Slide 38 of lecture 3)\n",
    "\n",
    "We can rewrite this expression with the last formula: \n",
    "\n",
    "$\\nabla^2 f_\\mu(\\mathbf{x}) =  \\mathbf{A}^T \\text{Diag}\\left(\\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1 - \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})) \\right)\\mathbf{A}+ \\mu \\mathbf{I}\\succeq \\mu \\mathbf{I}$\n",
    "\n",
    "So we have to proove that :\n",
    "\n",
    "$\\mathbf{A}^T \\text{Diag}\\left(\\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1 - \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})) \\right)\\mathbf{A}\\succeq \\mathbf{0}$\n",
    "\n",
    "Given that $\\sigma(x)$ is between $[0,1]$, we know that $\\text{Diag}\\left(\\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1 - \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})) \\right) \\succeq \\mathbf{0}$\n",
    "\n",
    "We can one more time rearrange the expression:\n",
    "$\\text{Diag}\\left(\\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1 - \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})) \\right) \\mathbf{A}^T \\mathbf{A}\\succeq \\mathbf{0}$, and now we only need to show that $\\mathbf{A}^T \\mathbf{A}\\succeq \\mathbf{0}$\n",
    "\n",
    "To show that, we write that for any vector $\\mathbf{x}$, we have $\\mathbf{x}^T\\mathbf{A}^T \\mathbf{A}\\mathbf{x}= (\\mathbf{A}\\mathbf{x})^T(\\mathbf{A}\\mathbf{x}) = \\sum_{i=1}^{n} (\\mathbf{a}_i^T\\mathbf{x})^2 \\geq 0 $, which means that $\\mathbf{A}^T \\mathbf{A}$ is positive semidefinite and we conclude that:\n",
    "\n",
    "$\\nabla^2 f_\\mu(\\mathbf{x})\\succeq \\mu \\mathbf{I}$ \n",
    "\n",
    "So $f_\\mu$ is $\\mu$-strongly convex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(i)__ (3 points) Is it possible for a strongly convex function to not attain its minimum ? <a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1) Justify your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from the course that if a function is strongly convex, it implies strict convexity, which means that if the minimum is reached, then it is unique.\n",
    "(lecture 3 page 36)\n",
    "\n",
    "A function is strongly convex if there exists a constant $\\mu>0$ such that for all $\\mathbf{x}, \\mathbf{y} \\in R^p$, we have: \n",
    "$f(\\mathbf{y}) \\geq f(\\mathbf{x}) + <\\nabla f(\\mathbf{x}), \\mathbf{y}-\\mathbf{x}> + \\frac{\\mu}{2} ||\\mathbf{y}-\\mathbf{x}||_2^2$\n",
    "\n",
    "This means that for any "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now show that $f_\\mu$ is smooth, i.e, $\\nabla f_\\mu$ is L-Lipschitz with respect to the Euclidean norm, with \n",
    "\\begin{equation}\n",
    "\tL = \\|A\\|^2_F + \\mu \\text{, where }\\|\\cdot\\|_F\\text{ denotes the Frobenius norm. }\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1 point for all three questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(j-1)__ Show that $\\lambda_{\\max}(\\mathbf{a}_i\\mathbf{a}_i^T) = \\left\\| \\mathbf{a}_i\\right\\|_2^2$, where $\\lambda_{\\max}(\\cdot)$ denotes the largest eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let say we have the eigenvalue $\\lambda$ and the eigenvector $\\mathbf{x}$ s.t $\\mathbf{a}_i\\mathbf{a}_i^T\\mathbf{x} = \\lambda \\mathbf{x}$\n",
    "\n",
    "We can then write: $\\mathbf{a}_i\\mathbf{a}_i^T\\mathbf{x} = c \\mathbf{a}_i$, with $c$ the result of $\\mathbf{a}_i^T\\mathbf{x}$. We notice that when $\\mathbf{x}$ is orthogonal to $\\mathbf{a}_i$, $c = 0$. With $\\mathbf{a}_i$ of dimension p, we have p-1 different normalized and non-colinear vectors that are orthogonal to $\\mathbf{a}_i$. So the last remaining vector that has a non-zero associated eigen value is $\\mathbf{x}= \\alpha \\mathbf{a}_i$\n",
    "\n",
    "We can then replace this value in the expression:  $\\mathbf{a}_i\\mathbf{a}_i^T\\mathbf{x} = \\mathbf{a}_i\\mathbf{a}_i^T \\alpha \\mathbf{a}_i = \\alpha \\left\\| \\mathbf{a}_i\\right\\|_2^2 \\mathbf{a}_i = \\left\\| \\mathbf{a}_i\\right\\|_2^2 \\mathbf{x}  $ and so we obtain that $\\lambda_{\\max}(\\mathbf{a}_i\\mathbf{a}_i^T) = \\left\\| \\mathbf{a}_i\\right\\|_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(j-2)__ Using [2](#mjx-eqn-eq2), show that $\\lambda_{\\max}(\\nabla^2 f_\\mu(\\mathbf{x})) \\leq \\sum_{i=1}^{n} \\|\\mathbf{a}_i\\|_2^2 + \\mu$. \n",
    "\n",
    "__Hint__: Recall that $\\lambda_{\\max}(\\cdot)$ verifies the triangle inequality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that $\\nabla^2 f_\\mu(\\mathbf{x}) = \\sum_{i=1}^{n} \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1 - \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x}))\\mathbf{a}_i\\mathbf{a}_i^T + \\mu \\mathbf{I}$\n",
    "\n",
    "The eigenvalues of $\\mu \\mathbf{I}$ are $\\mu$. We can also use the fact that $\\lambda_{\\max}(M_1 + M_2) \\leq \\lambda_{\\max}(M_1) + \\lambda_{\\max}(M_2)$\n",
    "\n",
    "From the last results, we obtain $\\lambda_{\\max}(\\nabla^2 f_\\mu(\\mathbf{x})) \\leq \\sum_{i=1}^{n} \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})(1 - \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x})) \\|\\mathbf{a}_i\\|_2^2 + \\mu$\n",
    "\n",
    "We also know that $\\sigma(x)(1-\\sigma(x))\\leq \\frac{1}{4}< 1$, so we can upper bound the last equation and obtain the desired expression:\n",
    "\n",
    "$\\lambda_{\\max}(\\nabla^2 f_\\mu(\\mathbf{x})) \\leq \\sum_{i=1}^{n} \\|\\mathbf{a}_i\\|_2^2 + \\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(j-3)__ Conclude that $f_\\mu$ is $L$-smooth for $L = \\|A\\|_F^2 + \\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f_\\mu$ is $L$-smooth if $\\nabla^2 f_\\mu(\\mathbf{x})\\preceq L \\mathbf{I}$\n",
    "\n",
    "We can then take the previous result: $L = \\sum_{i=1}^{n} \\|\\mathbf{a}_i\\|_2^2 + \\mu = \\sum_{i=1}^{n} \\sum_{j=1}^{p} |\\mathbf{a}_{i,j}|^2 + \\mu$.\n",
    "\n",
    "$\\sum_{i=1}^{n} \\sum_{j=1}^{p} |\\mathbf{a}_{i,j}|^2$ is by definition the denotes the square of the Frobenius norm of A. We can then conclude that:\n",
    "\n",
    "$L = \\|A\\|_F^2 + \\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(l)__ (2 point) To finalize, we introduce the Kullback-Leibler (KL) divergence. The KL divergence is a measure of how one probability distribution differs from a second, reference probability distribution. Along side the examples we saw in slide 18 of Lecture 1, the KL divergence is also a useful loss function to be used in learning frameworks.\n",
    "\n",
    "Write the definition of the Kullback-Leibler (KL) divergence between the true label distribution $q(b_i)$ and the model’s predicted distribution $p(b_i∣\\mathbf{a}_i)$ and show that minimizing the KL divergence between $q(b_i)$ and $p(b_i∣\\mathbf{a}_i)$ is equivalent to minimizing the negative log-likelihood derived in (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition:\n",
    "\n",
    "$D_{KL}(q \\| p) = \\sum_{i} q(b_i) \\log\\left( \\frac{q(b_i)}{p(b_i \\mid \\mathbf{a}_i)} \\right)$ , with true label distribution $ q(b_i)$ and the model’s predicted distribution $p(b_i \\mid \\mathbf{a}_i)$\n",
    "\n",
    "With this definition, we can develop:\n",
    "\n",
    "$D_{KL}(q \\| p) = \\sum_{i} q(b_i) \\log(q(b_i)) - \\sum_{i} q(b_i) \\log(p(b_i \\mid \\mathbf{a}_i))$\n",
    "\n",
    "The first term doesn't depend on the model's predicted distribution so we can remove it in the minimization problem formulation.\n",
    "\n",
    "$\\min D_{KL}(q \\| p) = - \\min \\sum_{i} q(b_i) \\log(p(b_i \\mid \\mathbf{a}_i))$\n",
    "\n",
    "From (a), we had:\n",
    "\n",
    "$f(\\mathbf{x}) = -\\log(\\mathbb{P}(b_1, \\dots, b_n | a_1, \\dots, a_n))  = - \\sum_{i=1}^n  \\log(p(b_i \\mid \\mathbf{a}_i))$\n",
    "\n",
    "Which is equivalent to minimizing the KL divergence between $q(b_i)$ and $p(b_i∣\\mathbf{a}_i)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From your work in this section, you have shown that the maximum likelihood estimator for logistic regression might not exist, but it can be guaranteed to exist by adding a $\\|\\cdot\\|_2^2$ regularizer. Consequently, the estimator for $\\mathbf{x}^\\natural$ we will use will be the solution of the smooth strongly convex problem,\n",
    "\\begin{equation}\n",
    "\t\\mathbf{x}^\\star=\\arg\\min_{\\mathbf{x} \\in \\mathbb{R}^p} f(\\mathbf{x}) + \\frac{\\mu}{2}\\|\\mathbf{x}\\|_2^2.\n",
    "\\tag{3}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1) TA's will give you candy if you provide a complete proof."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "custom_cell_magics": "kql"
  },
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
